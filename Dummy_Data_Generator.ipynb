{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPVYECgA+1x9kdRP9WG8n9M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crodier1/machine_learning_deep_learning/blob/main/Dummy_Data_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read this first\n",
        "Make sure you get a Deep Seek API Key and put it in the secrets. The chat bot will generate dummy data sets for you, but first proivde the column data types and the number of rows you need.\n",
        "\n"
      ],
      "metadata": {
        "id": "NDLzq1TRfA0O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lw7TpTCMnisU"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEEP_SEEK_API_KEY = userdata.get('DS_API_KEY')\n",
        "\n",
        "client = OpenAI(api_key=DEEP_SEEK_API_KEY, base_url=\"https://api.deepseek.com\")"
      ],
      "metadata": {
        "id": "5xvjaD6VpQgm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are a dummy data generator. Your task is to generate CSV files with fake but realistic test data.\n",
        "\n",
        "Rules:\n",
        "1. You require the following information from the user before generating data:\n",
        "   - Column names\n",
        "   - Data type for each column (e.g., string, integer, float, date, email, boolean)\n",
        "   - Number of rows to generate\n",
        "2. If the user provides only the number of columns and their data types (without names), you may auto-generate generic column names (e.g., col1, col2).\n",
        "3. If any required information is missing, do not generate the CSV. Instead, ask the user clearly and politely for the missing details.\n",
        "4. Always output the data in valid CSV format:\n",
        "   - First row = column headers\n",
        "   - Use commas as delimiters\n",
        "   - Quote values if necessary\n",
        "5. Generate realistic dummy values appropriate to the data type (e.g., names for strings, valid emails, plausible dates).\n",
        "6. Never invent assumptions beyond the provided schema. Always confirm missing details with the user.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "VHrV7DjFr_e8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "  try:\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = client.chat.completions.create(model=\"deepseek-chat\", messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"[ERROR] {type(e).__name__}: {e}\")\n",
        "    yield f\"[ERROR] {type(e).__name__}: {e}\""
      ],
      "metadata": {
        "id": "yZyll1zWsId6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_messages = [\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"Hi, let's make some dummy test data together. Please provide me with the name of the columns, data types, and how many rows you want.\"}\n",
        "]\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(value=initial_messages, type=\"messages\")\n",
        "    chat_interface = gr.ChatInterface(fn=chat, type=\"messages\", chatbot=chatbot)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "YiWzJhVQwn_c",
        "outputId": "c942b5a8-83a7-480c-ccfd-d832f6168649"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7a71ca8508a26598f5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7a71ca8508a26598f5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}